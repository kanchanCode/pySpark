{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "# Create SparkSession and sparkcontext\n",
    "from pyspark.sql import SparkSession\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark=SparkSession.builder\\\n",
    "      .master(\"local\")\\\n",
    "      .appName('firstprogram')\\\n",
    "      .getOrCreate()\n",
    "sc=spark.sparkContext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wordcount Program using a text file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the input file and Calculating words count\n",
    "text_file = sc.textFile(\"wordfile.txt\")\n",
    "counts = text_file.flatMap(lambda line: line.split(\" \")) \\\n",
    "                            .map(lambda word: (word, 1)) \\\n",
    "                           .reduceByKey(lambda x, y: x + y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.: 1\n",
      "Arjun: 2\n",
      "and: 21\n",
      "the: 48\n",
      "Bird’s: 1\n",
      "Eye: 1\n",
      "Test: 1\n",
      "The: 9\n",
      "Kauravas: 2\n",
      "Pandavas: 1\n",
      "were: 2\n",
      "given: 1\n",
      "an: 3\n",
      "archery: 3\n",
      "test: 2\n",
      "by: 3\n",
      "their: 2\n",
      "Guru,: 1\n",
      "Dronacharya.: 1\n",
      "They: 2\n",
      "asked: 6\n",
      "to: 21\n",
      "aim: 1\n",
      "at: 3\n",
      "eye: 1\n",
      "of: 16\n",
      "a: 13\n",
      "toy: 1\n",
      "bird: 1\n",
      "on: 1\n",
      "branch: 1\n",
      "tree.: 1\n",
      "When: 2\n",
      "teacher: 2\n",
      "them: 1\n",
      "what: 3\n",
      "they: 1\n",
      "saw,: 1\n",
      "with: 6\n",
      "exception: 1\n",
      "Arjun,: 2\n",
      "all: 1\n",
      "others: 1\n",
      "claimed: 1\n",
      "see: 1\n",
      "sky,: 1\n",
      "trees,: 1\n",
      "bird,: 1\n",
      "leaves,: 1\n",
      "branches,: 1\n",
      "etc.: 1\n",
      "Only: 2\n",
      "said: 1\n",
      "that: 4\n",
      "he: 11\n",
      "just: 1\n",
      "saw: 1\n",
      "blackness: 1\n",
      "bird’s: 1\n",
      "eye.: 1\n",
      "was: 7\n",
      "permitted: 1\n",
      "shoot: 1\n",
      "target,: 1\n",
      "which: 1\n",
      "did: 1\n",
      "successfully.: 1\n",
      ": 4\n",
      "2.: 1\n",
      "Abhimanyu: 2\n",
      "Chakravyuh: 1\n",
      "Abhimanyu,: 1\n",
      "while: 1\n",
      "in: 8\n",
      "his: 11\n",
      "mother’s: 1\n",
      "womb,: 1\n",
      "had: 3\n",
      "learned: 2\n",
      "how: 2\n",
      "break: 1\n",
      "Chakravyuh,: 1\n",
      "intricate: 1\n",
      "battle: 1\n",
      "formation.: 2\n",
      "On: 2\n",
      "thirteenth: 1\n",
      "day: 1\n",
      "great: 3\n",
      "battle,: 1\n",
      "sixteen-year-old: 1\n",
      "youth: 1\n",
      "fought: 1\n",
      "bravely: 1\n",
      "against: 2\n",
      "experienced,: 1\n",
      "much: 1\n",
      "older: 1\n",
      "warriors: 2\n",
      "reached: 1\n",
      "centre: 1\n",
      "circular: 1\n",
      "formation: 1\n",
      "where: 1\n",
      "Duryodhana: 2\n",
      "was.: 2\n",
      "rushed: 1\n",
      "save: 2\n",
      "attacked: 1\n",
      "Abhimanyu.: 1\n",
      "Unfortunately,: 1\n",
      "not: 3\n",
      "exit: 1\n",
      "He: 1\n",
      "put: 1\n",
      "up: 4\n",
      "fight: 1\n",
      "killed: 1\n",
      "many: 2\n",
      "before: 2\n",
      "himself: 3\n",
      "killed.: 1\n",
      "3.: 1\n",
      "Eklavya: 3\n",
      "Dronacharya: 5\n",
      "Eklavya,: 1\n",
      "tribal: 1\n",
      "boy: 1\n",
      "refused: 1\n",
      "be: 4\n",
      "taken: 1\n",
      "as: 4\n",
      "disciple: 1\n",
      "learn: 1\n",
      "Guru: 2\n",
      "who: 2\n",
      "taught: 1\n",
      "only: 2\n",
      "Kshatriyas: 1\n",
      "Brahmins.: 1\n",
      "Undeterred,: 1\n",
      "kept: 1\n",
      "clay: 1\n",
      "image: 2\n",
      "him: 6\n",
      "practised: 1\n",
      "becoming: 1\n",
      "very: 1\n",
      "proficient: 1\n",
      "it.: 2\n",
      "Once,: 1\n",
      "disturbed: 1\n",
      "barking: 1\n",
      "dog,: 1\n",
      "shot: 1\n",
      "arrows: 1\n",
      "its: 1\n",
      "mouth: 1\n",
      "shut: 1\n",
      "it: 2\n",
      "without: 2\n",
      "hurting: 1\n",
      "this: 3\n",
      "feat: 1\n",
      "came: 2\n",
      "into: 2\n",
      "notice: 1\n",
      "upset: 1\n",
      "there: 1\n",
      "better: 1\n",
      "archer: 2\n",
      "than: 1\n",
      "Not: 1\n",
      "wanting: 1\n",
      "have: 1\n",
      "rival: 1\n",
      "Arjuna: 1\n",
      "observing: 1\n",
      "teacher,: 1\n",
      "for: 7\n",
      "Dakshina,: 1\n",
      "offering: 2\n",
      "made: 1\n",
      "teacher.: 1\n",
      "being: 2\n",
      "could: 2\n",
      "offer,: 1\n",
      "right: 1\n",
      "thumb: 3\n",
      "knowing: 1\n",
      "well: 1\n",
      "shoot.: 1\n",
      "Without: 1\n",
      "hesitation,: 1\n",
      "cut: 1\n",
      "knife: 1\n",
      "placed: 1\n",
      "Guru’s: 1\n",
      "feet.: 1\n",
      "With: 1\n",
      "deed,: 1\n",
      "immortalized: 1\n",
      "epitome: 1\n",
      "ideal: 1\n",
      "student.: 1\n",
      "4.: 1\n",
      "Story: 1\n",
      "King: 2\n",
      "Shibi: 2\n",
      "known: 1\n",
      "truthfulness,: 1\n",
      "just,: 1\n",
      "keeping: 1\n",
      "word.: 1\n",
      "gods: 3\n",
      "Agni: 1\n",
      "Indra: 1\n",
      "decided: 1\n",
      "these: 1\n",
      "qualities.: 1\n",
      "assumed: 1\n",
      "forms: 2\n",
      "dove: 3\n",
      "hawk,: 1\n",
      "latter: 1\n",
      "pursuing: 1\n",
      "former.: 1\n",
      "sought: 2\n",
      "protection: 1\n",
      "Shibi,: 1\n",
      "promised: 1\n",
      "him.: 1\n",
      "hawk: 2\n",
      "anger: 1\n",
      "accused: 1\n",
      "depriving: 1\n",
      "rightful: 1\n",
      "food.: 1\n",
      "king,: 1\n",
      "reply,: 1\n",
      "offered: 1\n",
      "flesh: 3\n",
      "from: 3\n",
      "own: 1\n",
      "body: 1\n",
      "appease: 1\n",
      "hunger.: 1\n",
      "equal: 1\n",
      "weight: 1\n",
      "dove.: 1\n",
      "A: 2\n",
      "balance: 2\n",
      "brought,: 1\n",
      "king: 2\n",
      "started: 1\n",
      "cutting: 1\n",
      "body,: 1\n",
      "but: 2\n",
      "seemed: 1\n",
      "getting: 1\n",
      "heavier: 1\n",
      "every: 1\n",
      "piece.: 1\n",
      "Finally,: 1\n",
      "sat: 1\n",
      "entire: 1\n",
      "body.: 1\n",
      "At: 1\n",
      "this,: 1\n",
      "real: 1\n",
      "granting: 1\n",
      "boons: 1\n",
      "above,: 1\n",
      "witness: 1\n",
      "test,: 1\n",
      "showered: 1\n",
      "flowers: 1\n",
      "praise.: 1\n",
      "Moral: 1\n",
      "Lessons: 1\n",
      "Children: 1\n",
      "Mahabharata: 1\n",
      "Be: 1\n",
      "focused,: 1\n",
      "you: 4\n",
      "will: 7\n",
      "always: 2\n",
      "succeed.: 1\n",
      "can: 2\n",
      "guide: 1\n",
      "inspire: 1\n",
      "you,: 1\n",
      "practice: 1\n",
      "make: 1\n",
      "perfect.: 1\n",
      "Keep: 1\n",
      "good: 1\n",
      "company.: 1\n",
      "Bad: 1\n",
      "friends: 2\n",
      "bring: 3\n",
      "about: 1\n",
      "your: 3\n",
      "downfall.: 1\n",
      "Respect: 1\n",
      "women.: 1\n",
      "disrespect: 1\n",
      "shown: 1\n",
      "women: 1\n",
      "disasters: 1\n",
      "upon: 2\n",
      "you.: 1\n",
      "Don’t: 4\n",
      "indulge: 1\n",
      "vices: 1\n",
      "like: 1\n",
      "gambling.: 1\n",
      "You: 1\n",
      "end: 2\n",
      "losing: 1\n",
      "everything.: 1\n",
      "give: 1\n",
      "easily.: 1\n",
      "Fight: 1\n",
      "is: 2\n",
      "rightfully: 1\n",
      "yours.: 1\n",
      "Truth: 1\n",
      "wins: 1\n",
      "end.: 1\n",
      "apply: 1\n",
      "half-learned: 1\n",
      "knowledge: 1\n",
      "actions.: 1\n",
      "It: 2\n",
      "lead: 1\n",
      "failure.: 1\n",
      "support: 1\n",
      "wrong: 1\n",
      "acts: 1\n",
      "close: 1\n",
      "relatives.: 1\n",
      "trouble: 1\n",
      "well.: 1\n",
      "Do: 1\n",
      "seek: 1\n",
      "revenge.: 1\n",
      "Vengeance: 1\n",
      "spells: 1\n",
      "seeker: 1\n",
      "both.: 1\n",
      "War: 1\n",
      "never: 1\n",
      "good.: 1\n",
      "Matters: 1\n",
      "resolved: 1\n",
      "dialogue.: 1\n"
     ]
    }
   ],
   "source": [
    "output = counts.collect()\n",
    "for (word, count) in output:\n",
    "    print(\"%s: %i\" % (word, count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating RDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
      "<class 'pyspark.rdd.RDD'>\n",
      "[0, 1, 2, 3, 4]\n",
      "0\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "myrdd=spark.sparkContext.parallelize([0,1,2,3,4,5,6,7,8])\n",
    "print(myrdd.collect())\n",
    "print(type(myrdd))\n",
    "print(myrdd.take(5))\n",
    "print(myrdd.first())\n",
    "print(myrdd.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 2, 4, 6, 8]\n"
     ]
    }
   ],
   "source": [
    "myrdd2=myrdd.filter(lambda x: x%2==0)\n",
    "print(myrdd2.collect())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trying reading avro file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['PYSPARK_SUBMIT_ARGS'] = '--packages   org.apache.spark:spark avro_3.1:3.2  pyspark-shell'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "os.environ['PYSPARK_SUBMIT_ARGS'] = 'pyspark --packages org.apache.spark:spark-avro_2.12:2.4.2 pyspark-shell'\n",
    "from pyspark.sql.functions import *\n",
    "from py4j.protocol import Py4JJavaError\n",
    "import findspark\n",
    "findspark.init()\n",
    "# Create SparkSession and sparkcontext\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark=SparkSession.builder\\\n",
    "      .master(\"local\")\\\n",
    "      .appName('program')\\\n",
    "      .getOrCreate()\n",
    "sc=spark.sparkContext\n",
    "dataframe=spark.read.load(\"episodes.avro\")\n",
    "dataframe.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import findspark\n",
    "findspark.init()\n",
    "import os\n",
    "os.environ['PYSPARK_SUBMIT_ARGS'] = '--jars home/hdoop/spark/wordcount/spark-avro_2.13-3.2.1.jar'\n",
    "import pyspark\n",
    "#from pyspark import SparkConf, SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "path= \"home\\hdoop\\spark\\wordcount\"\n",
    "#Create SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "    .appName('DataFrame') \\\n",
    "    .master('local[*]')\\\n",
    "    .config('spark.jars','spark-avro_2.13-3.2.1.jar') \\\n",
    "    .getOrCreate()\n",
    "df=spark.read.load('userdata1.avro')\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkConf, SparkContext\n",
    "\n",
    "#Create SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "    .appName('DataFrame') \\\n",
    "    .master('local[*]')\\\n",
    "    .config('spark.jars', 'home/hdoop/spark/wordcount/spark-avro_2.11-2.4.4.jar') \\\n",
    "    .getOrCreate()\n",
    "\n",
    "\n",
    "df = spark.read.load('episodes.avro')\n",
    "\n",
    "df.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
